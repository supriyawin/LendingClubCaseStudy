# Loan Default Risk Analysis using Exploratory Data Analysis (EDA)
> This project aims to address real-world business challenges using Exploratory Data Analysis (EDA). Specifically, it focuses on risk analytics in the context of lending within a consumer finance company. By analyzing past loan applicant data, we aim to identify patterns that can predict whether a future applicant is likely to default on a loan. This understanding will enable the company to make informed decisions to minimize financial losses.


## Table of Contents
* [General Info](#general-information)
* [Technologies Used](#technologies-used)
* [Methodology](#methodology)

<!-- You can include any other section that is pertinent to your problem -->

## General Information
- The dataset provided contains information on past loan applicants, including their attributes and whether they defaulted on the loan..
- You are working for a consumer finance company that offers various types of loans to urban customers. When a loan application is received, the company faces two primary risks:You are working for a consumer finance company that offers various types of loans to urban customers. When a loan application is received, the company faces two primary risks:
  - **Risk of Loss of Business:** If a creditworthy applicant is denied a loan.
  - **Risk of Financial Loss:** If an applicant who is likely to default is approved for a loan.
- The dataset includes the following attributes:
  - **Consumer Attributes:** Information about the applicants such as age, income, employment details, etc.
  - **Loan Attributes:** Details about the loan applied for, including loan amount, interest rate, term, etc.
  - **Target Variable:** Whether the applicant defaulted on the loan (Yes/No).

## Methodology
The primary objective of this case study is to perform Exploratory Data Analysis to:
- Identifying the columns with all null values.
- Identifying the columns with no business significance.
- Write the meaning of the variables based on your interpretation.
- Data quality issue fixes:
  - Remove the null and insignificant columns
  - Change the data types of the required columns
  - Impute the values in the required columns
  - Duplicate removal
  - Outlier removal and treatment
- Univariate analysis (including the segmented univariate checks):
  - Frequency distribution for categorical variables (split across overall, default and non-default)
  - Frequency distribution for numerical variables (split across overall, default and non-default)
  - Checking the aggregated numerical metrics across the cohort (split across overall, default and non-default)
- Bivariate analysis
   

<!-- You don't have to answer all the questions - just the ones relevant to your project. -->

## Conclusions
- Conclusion 1 from the analysis
- Conclusion 2 from the analysis
- Conclusion 3 from the analysis
- Conclusion 4 from the analysis

<!-- You don't have to answer all the questions - just the ones relevant to your project. -->


## Technologies Used
The analysis will be conducted using Python programming language and its libraries, including:
- **Pandas** for data manipulation.
- **NumPy** for numerical operations.
- **Matplotlib** and **Seaborn** for data visualization.
- **Jupyter Notebooks** for interactive development and documentation.

<!-- As the libraries versions keep on changing, it is recommended to mention the version of library used in this project -->





